{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scr/utils\")\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from create_dataset import BirdDataset\n",
    "from base_utils import set_seed\n",
    "from metrics import validation_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Информация о процессоре: Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\n",
      "Доступно GPU: 1\n",
      "GPU 1: NVIDIA GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "# Информация о железе, на котором тестируется модель\n",
    "\n",
    "processor_info = platform.processor()\n",
    "print(\"Информация о процессоре:\", processor_info)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Доступно GPU:\", num_gpus)\n",
    "    for i in range(num_gpus):\n",
    "        gpu = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i + 1}: {gpu}\")   \n",
    "else:\n",
    "    print(\"GPU недоступны на данной системе.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df_test = df[df.fold == 3].reset_index(drop=True)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = torch.load(\"../experiment/14_September_2023_16_29/model_tf_efficientnet_b0_last_version.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = BirdDataset(df=df_test,\n",
    "                           path_to_folder_with_audio=\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(dataset_test,\n",
    "                          batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base.eval()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771/771 [03:21<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 4\n",
    "## Найдем скорость работы базовой модели на нашем валидационном датасете\n",
    "predicted_labels_list = None\n",
    "true_labels_list = None\n",
    "metric = validation_epoch_end\n",
    "start_time = time.time()\n",
    "\n",
    "model = model_base\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader):\n",
    "        X_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        res = model_base.forward(X_batch)\n",
    "\n",
    "        res = res.detach().cpu().sigmoid().numpy()\n",
    "        y_batch_onehot = y_batch\n",
    "        y_batch_onehot = y_batch_onehot.unsqueeze(1).detach().cpu().numpy()\n",
    "        y_batch_onehot = y_batch_onehot.squeeze()\n",
    "\n",
    "        if predicted_labels_list is None:\n",
    "            predicted_labels_list = res\n",
    "            true_labels_list = y_batch_onehot\n",
    "        else:\n",
    "            predicted_labels_list = np.concatenate([predicted_labels_list, res], axis=0)\n",
    "            true_labels_list = np.concatenate([true_labels_list, y_batch_onehot], axis=0)      \n",
    "\n",
    "        del batch, res\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_labels = np.vstack(predicted_labels_list)\n",
    "all_true_labels = np.vstack(true_labels_list)\n",
    "all_true_labels = np.squeeze(all_true_labels)\n",
    "mask = (all_true_labels > 0) & (all_true_labels < 1)\n",
    "all_true_labels[mask] = 0\n",
    "avg_metric = metric(all_true_labels, all_predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на базовой модели\n",
      "Время работы модели на всем батче 201.197 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.065 сек.\n",
      "Метрики качества\n",
      "metric val_RMAP : 0.670246\n",
      "metric CMAP_5 : 0.762456\n"
     ]
    }
   ],
   "source": [
    "# Мы понимаем, что ко времени работы модели добавляем время обработки батчей и добавления аугментаций к стартовым данным\n",
    "\n",
    "print(\"Наши метрики на базовой модели\")\n",
    "print(f\"Время работы модели на всем батче {t:.<2g} сек.\")\n",
    "print(f\"Время работы модели на одном сэмпле (AVG) {round(t/ len(dataset_test), 3) } сек.\")\n",
    "print(\"Метрики качества\")\n",
    "for m in avg_metric:\n",
    "    print(f\"metric {m} : {avg_metric[m]:.<5g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of parameters is 213\n"
     ]
    }
   ],
   "source": [
    "# Проверем производительность нашей модели, если мы будем учитывать все веса нашей модели только до тысячных.\n",
    "params = list(model.parameters()) \n",
    "print('the length of parameters is', len(params))\n",
    "for i in range(len(params)):\n",
    "    params[i].data = torch.round(params[i].data * 10 ** 3) / 10 ** 3\n",
    "    params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771/771 [03:16<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на базовой модели, с весами округленными до тысячных \n",
      "Время работы модели на всем батче 196.93 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.064 сек.\n",
      "Метрики качества\n",
      "metric val_RMAP : 0.667969\n",
      "metric CMAP_5 : 0.759319\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 4\n",
    "## Найдем скорость работы базовой модели на нашем валидационном датасете\n",
    "predicted_labels_list = None\n",
    "true_labels_list = None\n",
    "metric = validation_epoch_end\n",
    "start_time = time.time()\n",
    "\n",
    "model = model_base\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader):\n",
    "        X_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].to(device)\n",
    "        res = model_base.forward(X_batch)\n",
    "\n",
    "        res = res.detach().cpu().sigmoid().numpy()\n",
    "        y_batch_onehot = y_batch\n",
    "        y_batch_onehot = y_batch_onehot.unsqueeze(1).detach().cpu().numpy()\n",
    "        y_batch_onehot = y_batch_onehot.squeeze()\n",
    "\n",
    "        if predicted_labels_list is None:\n",
    "            predicted_labels_list = res\n",
    "            true_labels_list = y_batch_onehot\n",
    "        else:\n",
    "            predicted_labels_list = np.concatenate([predicted_labels_list, res], axis=0)\n",
    "            true_labels_list = np.concatenate([true_labels_list, y_batch_onehot], axis=0)      \n",
    "\n",
    "        del batch, res\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "all_predicted_labels = np.vstack(predicted_labels_list)\n",
    "all_true_labels = np.vstack(true_labels_list)\n",
    "all_true_labels = np.squeeze(all_true_labels)\n",
    "mask = (all_true_labels > 0) & (all_true_labels < 1)\n",
    "all_true_labels[mask] = 0\n",
    "avg_metric = metric(all_true_labels, all_predicted_labels)\n",
    "\n",
    "t = end_time - start_time\n",
    "\n",
    "# Мы понимаем, что ко времени работы модели добавляем время обработки батчей и добавления аугментаций к стартовым данным\n",
    "\n",
    "print(\"Наши метрики на базовой модели, с весами округленными до тысячных \")\n",
    "print(f\"Время работы модели на всем батче {t:.<2g} сек.\")\n",
    "print(f\"Время работы модели на одном сэмпле (AVG) {round(t/ len(dataset_test), 3) } сек.\")\n",
    "print(\"Метрики качества\")\n",
    "for m in avg_metric:\n",
    "    print(f\"metric {m} : {avg_metric[m]:.<5g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
