{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T14:54:00.526234Z",
     "start_time": "2023-09-16T14:53:58.867470Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scr/utils\")\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from create_dataset import BirdDataset\n",
    "from base_utils import set_seed\n",
    "from metrics import validation_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T14:54:00.529538Z",
     "start_time": "2023-09-16T14:54:00.527397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Информация о процессоре: arm\n",
      "GPU недоступны на данной системе.\n"
     ]
    }
   ],
   "source": [
    "# Информация о железе, на котором тестируется модель\n",
    "\n",
    "processor_info = platform.processor()\n",
    "print(\"Информация о процессоре:\", processor_info)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Доступно GPU:\", num_gpus)\n",
    "    for i in range(num_gpus):\n",
    "        gpu = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i + 1}: {gpu}\")   \n",
    "else:\n",
    "    print(\"GPU недоступны на данной системе.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T14:54:00.823655Z",
     "start_time": "2023-09-16T14:54:00.530870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df_test = df[df.fold == 3].sample(n=100, random_state=42).reset_index(drop=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_base = torch.load(\"../experiment/14_September_2023_16_29/model_tf_efficientnet_b0_last_version.pt\", map_location=device).to(device)\n",
    "dataset_test = BirdDataset(df=df_test, path_to_folder_with_audio=\"../data\")\n",
    "valid_loader = DataLoader(dataset_test, batch_size=4)\n",
    "model_base.eval()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Проверим работу базовой модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T14:54:02.075201Z",
     "start_time": "2023-09-16T14:54:02.049609Z"
    }
   },
   "outputs": [],
   "source": [
    "model = deepcopy(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:07:21.259954Z",
     "start_time": "2023-09-16T15:07:21.254879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T15:07:21.542752Z",
     "start_time": "2023-09-16T15:07:21.538660Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metric_score(model):\n",
    "    predicted_labels_list = None\n",
    "    true_labels_list = None\n",
    "    metric = validation_epoch_end\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            X_batch = batch[0].to(device)\n",
    "            y_batch = batch[1].to(device)\n",
    "            res = model.forward(X_batch)\n",
    "\n",
    "            res = res.detach().sigmoid().cpu().numpy()\n",
    "            y_batch_onehot = y_batch\n",
    "            y_batch_onehot = y_batch_onehot.unsqueeze(1).detach().cpu().numpy()\n",
    "            y_batch_onehot = y_batch_onehot.squeeze()\n",
    "\n",
    "            if predicted_labels_list is None:\n",
    "                predicted_labels_list = res\n",
    "                true_labels_list = y_batch_onehot\n",
    "            else:\n",
    "                predicted_labels_list = np.concatenate([predicted_labels_list, res], axis=0)\n",
    "                true_labels_list = np.concatenate([true_labels_list, y_batch_onehot], axis=0)\n",
    "\n",
    "            del batch, res\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    all_predicted_labels = np.vstack(predicted_labels_list)\n",
    "    all_true_labels = np.vstack(true_labels_list)\n",
    "    all_true_labels = np.squeeze(all_true_labels)\n",
    "    mask = (all_true_labels > 0) & (all_true_labels < 1)\n",
    "    all_true_labels[mask] = 0\n",
    "    avg_metric = metric(all_true_labels, all_predicted_labels)\n",
    "    t = end_time - start_time\n",
    "\n",
    "    # Мы понимаем, что ко времени работы модели добавляем время обработки батчей и добавления аугментаций к стартовым данным\n",
    "\n",
    "    print(\"Наши метрики на нашей базовой модели:\")\n",
    "    print(f\"Время работы модели на всем батче {t:.<2g} сек.\")\n",
    "    print(f\"Время работы модели на одном сэмпле (AVG) {round(t/ len(dataset_test), 3) } сек.\")\n",
    "    print(\"Метрики качества:\")\n",
    "    for m in avg_metric:\n",
    "        print(f\"metric {m} : {avg_metric[m]:.<5g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.738MB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model=model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:06:04.869839Z",
     "start_time": "2023-09-16T15:06:04.834360Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T15:06:04.831621Z",
     "start_time": "2023-09-16T15:05:41.940213Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:22<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на нашей базовой модели:\n",
      "Время работы модели на всем батче 22.8778 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.229 сек.\n",
      "Метрики качества:\n",
      "metric val_RMAP : 0.746389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_metric_score(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PTDQ  fp32 -> qint8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model = deepcopy(model_base)\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "    model,  # the original model\n",
    "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8  # the target dtype for quantized weights\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:06:50.769477Z",
     "start_time": "2023-09-16T15:06:50.713465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 15.448MB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model=model_int8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:08:15.152667Z",
     "start_time": "2023-09-16T15:08:15.131657Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s][W qlinear_dynamic.cpp:247] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "100%|██████████| 25/25 [00:24<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на нашей базовой модели:\n",
      "Время работы модели на всем батче 24.4309 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.244 сек.\n",
      "Метрики качества:\n",
      "metric val_RMAP : 0.738694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_metric_score(model=model_int8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:08:43.217061Z",
     "start_time": "2023-09-16T15:08:18.774596Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Незначительное уменьшение веса модели и метрики"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PTDS  fp32 -> qint8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "model = deepcopy(model_base)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:15:58.742728Z",
     "start_time": "2023-09-16T15:15:58.702018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model.eval();"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:15:58.939861Z",
     "start_time": "2023-09-16T15:15:58.934907Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "did not find fuser method for: (<class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.container.Sequential'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.DepthwiseSeparableConv'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.adaptive_avgmax_pool.SelectAdaptivePool2d'>, <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>, <class 'torch.nn.modules.flatten.Flatten'>, <class 'torch.nn.modules.container.Sequential'>, <class 'torch.nn.modules.linear.Linear'>) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[70], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mqconfig \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mao\u001B[38;5;241m.\u001B[39mquantization\u001B[38;5;241m.\u001B[39mget_default_qconfig(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx86\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Fuse the activations to preceding layers, where applicable.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# This needs to be done manually depending on the model architecture.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Common fusions include `conv + relu` and `conv + batchnorm + relu`\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m model_fp32_fused \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mao\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfuse_modules\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnamed_modules\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Prepare the model for static quantization. This inserts observers in\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# the model that will observe activation tensors during calibration.\u001B[39;00m\n\u001B[1;32m     10\u001B[0m model_fp32_prepared \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mao\u001B[38;5;241m.\u001B[39mquantization\u001B[38;5;241m.\u001B[39mprepare(model_fp32_fused)\n",
      "File \u001B[0;32m~/PycharmProjects/model_compression/venv/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:158\u001B[0m, in \u001B[0;36mfuse_modules\u001B[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfuse_modules\u001B[39m(model, modules_to_fuse, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, fuser_func\u001B[38;5;241m=\u001B[39mfuse_known_modules, fuse_custom_config_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Fuses a list of modules into a single module\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    Fuses only the following sequence of modules:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    156\u001B[0m \n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_fuse_modules\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodules_to_fuse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_qat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfuser_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfuser_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfuse_custom_config_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/model_compression/venv/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:100\u001B[0m, in \u001B[0;36m_fuse_modules\u001B[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;66;03m# Handle case of modules_to_fuse being a list of lists\u001B[39;00m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module_list \u001B[38;5;129;01min\u001B[39;00m modules_to_fuse:\n\u001B[0;32m--> 100\u001B[0m         \u001B[43m_fuse_modules_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_qat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuser_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuse_custom_config_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/PycharmProjects/model_compression/venv/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:84\u001B[0m, in \u001B[0;36m_fuse_modules_helper\u001B[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001B[0m\n\u001B[1;32m     81\u001B[0m     mod_list\u001B[38;5;241m.\u001B[39mappend(_get_module(model, item))\n\u001B[1;32m     83\u001B[0m \u001B[38;5;66;03m# Fuse list of modules\u001B[39;00m\n\u001B[0;32m---> 84\u001B[0m new_mod_list \u001B[38;5;241m=\u001B[39m \u001B[43mfuser_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmod_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_qat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madditional_fuser_method_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m# Replace original module list with fused module list\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(modules_to_fuse):\n",
      "File \u001B[0;32m~/PycharmProjects/model_compression/venv/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:52\u001B[0m, in \u001B[0;36mfuse_known_modules\u001B[0;34m(mod_list, is_qat, additional_fuser_method_mapping)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Returns a list of modules that fuses the operations specified\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m in the input module list.\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03mthe fused operation. The rest of the elements are set to nn.Identity()\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     51\u001B[0m types \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(type_before_parametrizations(m) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m mod_list)\n\u001B[0;32m---> 52\u001B[0m fuser_method \u001B[38;5;241m=\u001B[39m \u001B[43mget_fuser_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madditional_fuser_method_mapping\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fuser_method \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot fuse modules: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(types))\n",
      "File \u001B[0;32m~/PycharmProjects/model_compression/venv/lib/python3.10/site-packages/torch/ao/quantization/fuser_method_mappings.py:190\u001B[0m, in \u001B[0;36mget_fuser_method\u001B[0;34m(op_list, additional_fuser_method_mapping)\u001B[0m\n\u001B[1;32m    187\u001B[0m all_mappings \u001B[38;5;241m=\u001B[39m get_combined_dict(_DEFAULT_OP_LIST_TO_FUSER_METHOD,\n\u001B[1;32m    188\u001B[0m                                  additional_fuser_method_mapping)\n\u001B[1;32m    189\u001B[0m fuser_method \u001B[38;5;241m=\u001B[39m all_mappings\u001B[38;5;241m.\u001B[39mget(op_list, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 190\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m fuser_method \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdid not find fuser method for: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(op_list)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fuser_method\n",
      "\u001B[0;31mAssertionError\u001B[0m: did not find fuser method for: (<class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.container.Sequential'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.DepthwiseSeparableConv'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.conv2d_same.Conv2dSame'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.container.Sequential'>, <class 'timm.models._efficientnet_blocks.InvertedResidual'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.models._efficientnet_blocks.SqueezeExcite'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.activation.Sigmoid'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.conv.Conv2d'>, <class 'timm.layers.norm_act.BatchNormAct2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.activation.SiLU'>, <class 'timm.layers.adaptive_avgmax_pool.SelectAdaptivePool2d'>, <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>, <class 'torch.nn.modules.flatten.Flatten'>, <class 'torch.nn.modules.container.Sequential'>, <class 'torch.nn.modules.linear.Linear'>) "
     ]
    }
   ],
   "source": [
    "model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
    "# Fuse the activations to preceding layers, where applicable.\n",
    "# This needs to be done manually depending on the model architecture.\n",
    "# Common fusions include `conv + relu` and `conv + batchnorm + relu`\n",
    "model_fp32_fused = torch.ao.quantization.fuse_modules(model, [[name for name, _ in model.named_modules() if name != '']])\n",
    "\n",
    "# Prepare the model for static quantization. This inserts observers in\n",
    "# the model that will observe activation tensors during calibration.\n",
    "model_fp32_prepared = torch.ao.quantization.prepare(model_fp32_fused)\n",
    "\n",
    "# calibrate the prepared model to determine quantization parameters for activations\n",
    "# in a real world setting, the calibration would be done with a representative dataset\n",
    "input_fp32 = torch.randn(4, 1, 4, 4)\n",
    "model_fp32_prepared(input_fp32)\n",
    "\n",
    "# Convert the observed model to a quantized model. This does several things:\n",
    "# quantizes the weights, computes and stores the scale and bias value to be\n",
    "# used with each activation tensor, and replaces key operators with quantized\n",
    "# implementations.\n",
    "model_int8 = torch.ao.quantization.convert(model_fp32_prepared)\n",
    "\n",
    "# run the model, relevant calculations will happen in int8\n",
    "res = model_int8(input_fp32);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T15:30:27.627842Z",
     "start_time": "2023-09-16T15:30:27.559528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_model_size(model=model_int8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_metric_score(model=model_int8)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
