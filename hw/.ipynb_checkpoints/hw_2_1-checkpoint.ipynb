{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:16.873004Z",
     "start_time": "2023-09-24T12:54:12.905501Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../scr/utils\")\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from scr.utils.create_dataset import BirdDataset\n",
    "from scr.utils.metrics import validation_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:16.876374Z",
     "start_time": "2023-09-24T12:54:16.874296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Информация о процессоре: i386\n",
      "GPU недоступны на данной системе.\n"
     ]
    }
   ],
   "source": [
    "# Информация о железе, на котором тестируется модель\n",
    "\n",
    "processor_info = platform.processor()\n",
    "print(\"Информация о процессоре:\", processor_info)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Доступно GPU:\", num_gpus)\n",
    "    for i in range(num_gpus):\n",
    "        gpu = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i + 1}: {gpu}\")   \n",
    "else:\n",
    "    print(\"GPU недоступны на данной системе.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:17.264506Z",
     "start_time": "2023-09-24T12:54:16.878425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df_test = df[df.fold == 3].sample(n=100, random_state=42).reset_index(drop=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_base = torch.load(\"../experiment/14_September_2023_16_29/model_tf_efficientnet_b0_last_version.pt\", map_location=device).to(device)\n",
    "dataset_test = BirdDataset(df=df_test, path_to_folder_with_audio=\"../data/data/\")\n",
    "valid_loader = DataLoader(dataset_test, batch_size=4)\n",
    "model_base.eval()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:17.304128Z",
     "start_time": "2023-09-24T12:54:17.283490Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:17.310032Z",
     "start_time": "2023-09-24T12:54:17.288889Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metric_score(model):\n",
    "    predicted_labels_list = None\n",
    "    true_labels_list = None\n",
    "    metric = validation_epoch_end\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            X_batch = batch[0].to(device)\n",
    "            y_batch = batch[1].to(device)\n",
    "            res = model.forward(X_batch)\n",
    "\n",
    "            res = res.detach().sigmoid().cpu().numpy()\n",
    "            y_batch_onehot = y_batch\n",
    "            y_batch_onehot = y_batch_onehot.unsqueeze(1).detach().cpu().numpy()\n",
    "            y_batch_onehot = y_batch_onehot.squeeze()\n",
    "\n",
    "            if predicted_labels_list is None:\n",
    "                predicted_labels_list = res\n",
    "                true_labels_list = y_batch_onehot\n",
    "            else:\n",
    "                predicted_labels_list = np.concatenate([predicted_labels_list, res], axis=0)\n",
    "                true_labels_list = np.concatenate([true_labels_list, y_batch_onehot], axis=0)\n",
    "\n",
    "            del batch, res\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    all_predicted_labels = np.vstack(predicted_labels_list)\n",
    "    all_true_labels = np.vstack(true_labels_list)\n",
    "    all_true_labels = np.squeeze(all_true_labels)\n",
    "    mask = (all_true_labels > 0) & (all_true_labels < 1)\n",
    "    all_true_labels[mask] = 0\n",
    "    avg_metric = metric(all_true_labels, all_predicted_labels)\n",
    "    t = end_time - start_time\n",
    "\n",
    "    # Мы понимаем, что ко времени работы модели добавляем время обработки батчей и добавления аугментаций к стартовым данным\n",
    "\n",
    "    print(\"Наши метрики на нашей базовой модели:\")\n",
    "    print(f\"Время работы модели на всем батче {t:.<2g} сек.\")\n",
    "    print(f\"Время работы модели на одном сэмпле (AVG) {round(t/ len(dataset_test), 3) } сек.\")\n",
    "    print(\"Метрики качества:\")\n",
    "    for m in avg_metric:\n",
    "        print(f\"metric {m} : {avg_metric[m]:.<5g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверим работу базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepcopy(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:18.144516Z",
     "start_time": "2023-09-24T12:54:18.137365Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.738MB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:46.234853Z",
     "start_time": "2023-09-24T12:54:18.934384Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на нашей базовой модели:\n",
      "Время работы модели на всем батче 16.9049 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.169 сек.\n",
      "Метрики качества:\n",
      "metric val_RMAP : 0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_metric_score(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTDQ  fp32 -> float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.quantized.engine = \"fbgemm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = deepcopy(model_base)\n",
    "# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fp16 = torch.ao.quantization.quantize_dynamic(\n",
    "#     model,  # the original model\n",
    "#     {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "#     dtype=torch.float16  # the target dtype for quantized weights\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_model_size(model=model_fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_metric_score(model=model_fp16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## PTDQ  fp32 -> qint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'qnnpack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepcopy(model_base)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:46.297321Z",
     "start_time": "2023-09-24T12:54:46.237074Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "    model,  # the original model\n",
    "    {torch.nn.Linear},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8  # the target dtype for quantized weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:54:46.302126Z",
     "start_time": "2023-09-24T12:54:46.298921Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 15.448MB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model=model_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T12:55:09.810815Z",
     "start_time": "2023-09-24T12:54:46.302388Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:13<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на нашей базовой модели:\n",
      "Время работы модели на всем батче 13.4183 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.134 сек.\n",
      "Метрики качества:\n",
      "metric val_RMAP : 0.689346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_metric_score(model=model_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Незначительное уменьшение веса модели и метрики, на 5 секунд уменьшилось время на батче"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## PTSQ  fp32 -> qint8\n",
    "## QAT  fp32 -> qint8\n",
    "\n",
    "Нельзя провести qat и ptsq так как у timm моделей нет шага с fuse_model \\\n",
    "референс тут https://github.com/huggingface/pytorch-image-models/issues/204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T13:00:39.174806Z",
     "start_time": "2023-09-24T13:00:38.947316Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = deepcopy(model_base)\n",
    "def get_prunable_parameters(model, pruning_method, amount):\n",
    "    prunable_parameters = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "            prunable_parameters.append((module, 'weight'))\n",
    "\n",
    "    pruned_parameters = [(module, param_name) for module, param_name in prunable_parameters]\n",
    "    prune.global_unstructured(\n",
    "        pruned_parameters,\n",
    "        pruning_method=pruning_method,\n",
    "        amount=amount,\n",
    "    )\n",
    "\n",
    "    return pruned_parameters, model\n",
    "\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "pruned_parameters, model = get_prunable_parameters(model, prune.L1Unstructured, 0.2)\n",
    "for module, param_name in pruned_parameters:\n",
    "    prune.remove(module, \"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T13:00:40.474830Z",
     "start_time": "2023-09-24T13:00:40.470983Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 16.738MB\n"
     ]
    }
   ],
   "source": [
    "get_model_size(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-24T13:01:03.701641Z",
     "start_time": "2023-09-24T13:00:41.591893Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:13<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наши метрики на нашей базовой модели:\n",
      "Время работы модели на всем батче 13.3535 сек.\n",
      "Время работы модели на одном сэмпле (AVG) 0.134 сек.\n",
      "Метрики качества:\n",
      "metric val_RMAP : 0.656841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_metric_score(model=model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Незначительное уменьшение метрики, на 5 секунд уменьшилось время на батче"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
