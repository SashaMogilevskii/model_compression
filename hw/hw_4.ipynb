{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70cffc97-9c77-49c1-bdcc-496fd4e2a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from box import Box\n",
    "from torch.utils.data import DataLoader\n",
    "from loguru import logger\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../scr/\")\n",
    "sys.path.append(\"..\")\n",
    "from utils.create_dataset import BirdDataset\n",
    "from utils.base_utils import set_seed\n",
    "from utils.metrics import validation_epoch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314cab9b-7789-4e50-bfd5-9db7dd1a6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-23 17:25:46.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.base_utils\u001b[0m:\u001b[36mset_seed\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mSet seed: 1771\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Наш конфиг для обучения модели \n",
    "class Config():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    debug= False\n",
    "    seed = 1771\n",
    "    path_to_files_base = \"../data\"\n",
    "    batch_size = 4\n",
    "    optimizer_lr = 0.006\n",
    "    optimizer_wd = 0\n",
    "    scheduler = \"CosineAnnealingWarmRestarts\"\n",
    "    metric = \"custom\"\n",
    "    loss_f = \"nn.BCEWithLogitsLoss()\"\n",
    "    optimizer = \"Adam\"\n",
    "    epochs = 5\n",
    "    num_workers = 0\n",
    "config = Config()\n",
    "set_seed(seed=config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d0837d-e790-4393-8105-3cf4d05eaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вернемся к нашему датасету. \n",
    "# Наша модель учитель была модель tf_efficientnet_b4. \n",
    "# tf_efficientnet_b0 - будет нашей моделью учеником. \n",
    "# Подгрузим нашу модель учителя, и наш датасет в таком же соотношения, как обучалась наша модель учитель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565abf0d-3e09-4efc-b930-f2e9bd758d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-23 17:25:47.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mScheduler - CosineAnnealingWarmRestarts\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# load models\n",
    "\n",
    "model_teacher = torch.load(\"../experiment/23_October_2023_14_17/model_tf_efficientnet_b4_last_version.pt\", map_location=config.device).to(config.device)\n",
    "model_student = timm.create_model(\"tf_efficientnet_b0\", pretrained=True).to(config.device)\n",
    "model_student.classifier = nn.Sequential(\n",
    "        nn.Linear(model_student.classifier.in_features, 264)\n",
    "    )\n",
    "\n",
    "model_teacher.to(config.device)\n",
    "model_student.to(config.device)\n",
    "\n",
    "metric = validation_epoch_end\n",
    "optimizer = torch.optim.Adam(model_student.parameters(),\n",
    "                                     lr=config.optimizer_lr,\n",
    "                                     weight_decay=config.optimizer_wd\n",
    "                                     )\n",
    "loss_f = nn.BCEWithLogitsLoss() \n",
    "    \n",
    "logger.info(f\"Scheduler - {config.scheduler}\")\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer,\n",
    "                                        T_0=10,\n",
    "                                        T_mult=2,\n",
    "                                        eta_min=0.000001,\n",
    "                                        last_epoch=-1)\n",
    "model_teacher.eval()\n",
    "\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1291692-0e7b-41ac-b1a8-58df8d3c2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationKnowledgeDistillationTrainer():\n",
    "    def __init__(self, teacher_model, alpha, temperature):\n",
    "        self.teacher_model = teacher_model\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def compute_loss(self, model,  X_batch, y_batch, return_outputs=False):\n",
    "        # Extract logits and loss from student model\n",
    "        outputs_student = model.forward(X_batch)\n",
    "        logits_student = outputs_student\n",
    "        loss_f = nn.BCEWithLogitsLoss() \n",
    "        loss_ce = loss_f(outputs_student.float(), y_batch)\n",
    "\n",
    "        # Extract logits from teacher model\n",
    "        outputs_teacher = self.teacher_model(X_batch)\n",
    "        logits_teacher = outputs_teacher\n",
    "\n",
    "        # Compute distillation loss using Kullback-Leibler Divergence\n",
    "        loss_fct = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        loss_kd = self.temperature ** 2 * loss_fct(\n",
    "            F.log_softmax(logits_student / self.temperature, dim=-1),\n",
    "            F.softmax(logits_teacher / self.temperature, dim=-1)\n",
    "        )\n",
    "\n",
    "        # Combine classification loss and distillation loss with a weight (alpha)\n",
    "        loss = self.alpha * loss_ce + (1. - self.alpha) * loss_kd\n",
    "\n",
    "        return (loss, outputs_student) if return_outputs else loss\n",
    "        \n",
    "trainer_for_find_loss = ImageClassificationKnowledgeDistillationTrainer(\n",
    "    teacher_model=model_teacher,\n",
    "    alpha=0.5,\n",
    "    temperature=2.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3afdb5-6960-45ce-8575-e1bb78fb09c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-23 17:25:47.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mSize df_train- 12326\u001b[0m\n",
      "\u001b[32m2023-10-23 17:25:47.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mSize df_test- 3082\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load datasets \n",
    "df = pd.read_csv(\"../data/data.csv\")\n",
    "df_train, df_test = (df[df.fold != 3].reset_index(drop=True),\n",
    "                     df[df.fold == 3].reset_index(drop=True)\n",
    "                     )\n",
    "\n",
    "logger.info(f\"Size df_train- {df_train.shape[0]}\")\n",
    "logger.info(f\"Size df_test- {df_test.shape[0]}\")\n",
    "\n",
    "dataset_train = BirdDataset(df=df_train,\n",
    "                            path_to_folder_with_audio=config.path_to_files_base\n",
    "                            )\n",
    "dataset_test = BirdDataset(df=df_test,\n",
    "                           path_to_folder_with_audio=config.path_to_files_base\n",
    "                           )\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=config.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=config.num_workers)\n",
    "valid_loader = DataLoader(dataset_test,\n",
    "                          batch_size=config.batch_size,\n",
    "                          num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f0232-98df-4686-a8f7-000b9a112699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-23 17:25:47.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m---------------------epoch:1/5---------------------\u001b[0m\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3082/3082 [19:51<00:00,  2.59it/s, gpu_load=2.13GB, loss=0.7887]\n",
      "\u001b[32m2023-10-23 17:50:05.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mepoch: 1\u001b[0m\n",
      "\u001b[32m2023-10-23 17:50:05.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mloss_train: 1.8046| loss_valid: 1.3870|\u001b[0m\n",
      "\u001b[32m2023-10-23 17:50:05.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mmetric val_RMAP : 0.283333\u001b[0m\n",
      "\u001b[32m2023-10-23 17:50:05.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mElapsed time: 00:24:18\u001b[0m\n",
      "\u001b[32m2023-10-23 17:50:05.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m---------------------epoch:2/5---------------------\u001b[0m\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3082/3082 [19:04<00:00,  2.69it/s, gpu_load=2.13GB, loss=1.1726]\n",
      "\u001b[32m2023-10-23 18:12:56.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mepoch: 2\u001b[0m\n",
      "\u001b[32m2023-10-23 18:12:56.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mloss_train: 1.0684| loss_valid: 0.9264|\u001b[0m\n",
      "\u001b[32m2023-10-23 18:12:56.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mmetric val_RMAP : 0.335268\u001b[0m\n",
      "\u001b[32m2023-10-23 18:12:56.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mElapsed time: 00:22:50\u001b[0m\n",
      "\u001b[32m2023-10-23 18:12:56.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m---------------------epoch:3/5---------------------\u001b[0m\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3082/3082 [18:17<00:00,  2.81it/s, gpu_load=2.13GB, loss=1.3157]\n",
      "\u001b[32m2023-10-23 18:35:57.968\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mepoch: 3\u001b[0m\n",
      "\u001b[32m2023-10-23 18:35:57.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mloss_train: 0.7806| loss_valid: 0.6929|\u001b[0m\n",
      "\u001b[32m2023-10-23 18:35:57.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mmetric val_RMAP : 0.383982\u001b[0m\n",
      "\u001b[32m2023-10-23 18:35:57.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mElapsed time: 00:23:01\u001b[0m\n",
      "\u001b[32m2023-10-23 18:35:57.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m---------------------epoch:4/5---------------------\u001b[0m\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3082/3082 [20:16<00:00,  2.53it/s, gpu_load=2.13GB, loss=1.3877]\n",
      "\u001b[32m2023-10-23 19:01:05.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m96\u001b[0m - \u001b[1mepoch: 4\u001b[0m\n",
      "\u001b[32m2023-10-23 19:01:05.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mloss_train: 0.7471| loss_valid: 0.8913|\u001b[0m\n",
      "\u001b[32m2023-10-23 19:01:05.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mmetric val_RMAP : 0.374916\u001b[0m\n",
      "\u001b[32m2023-10-23 19:01:05.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mElapsed time: 00:25:07\u001b[0m\n",
      "\u001b[32m2023-10-23 19:01:05.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1m---------------------epoch:5/5---------------------\u001b[0m\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3082/3082 [19:06<00:00,  2.69it/s, gpu_load=2.13GB, loss=2.3895]\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(1, config.epochs + 1):\n",
    "    k = 0\n",
    "    start = time.time()\n",
    "    logger.info(f'---------------------epoch:{epoch_i}/{config.epochs}---------------------')\n",
    "\n",
    "    # loss\n",
    "    avg_train_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    predicted_labels_list = None\n",
    "    true_labels_list = None\n",
    "\n",
    "    ############## Train #############\n",
    "    model_student.train()\n",
    "    train_pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch in train_pbar:\n",
    "        X_batch = batch[0].to(config.device)\n",
    "        y_batch = batch[1].to(config.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, res = trainer_for_find_loss.compute_loss(\n",
    "            model=model_student,\n",
    "            X_batch=X_batch,\n",
    "            y_batch=y_batch,\n",
    "            return_outputs=True\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            train_pbar.set_postfix(gpu_load=f\"{torch.cuda.memory_allocated() / 1024 ** 3:.2f}GB\",\n",
    "                                   loss=f\"{loss.item():.4f}\")\n",
    "        else:\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_train_loss += loss * len(y_batch)\n",
    "        del batch, res\n",
    "\n",
    "        if config.scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if config.debug:\n",
    "            k += 1\n",
    "            if k > 5:\n",
    "                break\n",
    "\n",
    "    model_student.eval()\n",
    "\n",
    "    ########## VALIDATION ###############\n",
    "    with torch.no_grad():\n",
    "        for batch in (valid_loader):\n",
    "            X_batch = batch[0].to(config.device)\n",
    "            y_batch = batch[1].to(config.device)\n",
    "\n",
    "            loss, res = trainer_for_find_loss.compute_loss(\n",
    "            model=model_student,\n",
    "            X_batch=X_batch,\n",
    "            y_batch=y_batch,\n",
    "            return_outputs=True\n",
    "        )\n",
    "            y_batch_onehot = y_batch\n",
    "\n",
    "            avg_val_loss += loss * len(y_batch)\n",
    "\n",
    "            # metrics\n",
    "            res = res.detach().cpu().sigmoid().numpy()\n",
    "            y_batch_onehot = y_batch_onehot.unsqueeze(1).detach().cpu().numpy()\n",
    "            y_batch_onehot = y_batch_onehot.squeeze()\n",
    "\n",
    "            if predicted_labels_list is None:\n",
    "                predicted_labels_list = res\n",
    "                true_labels_list = y_batch_onehot\n",
    "            else:\n",
    "                predicted_labels_list = np.concatenate([predicted_labels_list, res], axis=0)\n",
    "                true_labels_list = np.concatenate([true_labels_list, y_batch_onehot], axis=0)\n",
    "\n",
    "            del batch, res\n",
    "\n",
    "            if config.debug:\n",
    "                k += 1\n",
    "                if k > 10:\n",
    "                    break\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss = avg_train_loss / len(dataset_train)\n",
    "    avg_val_loss = avg_val_loss / len(dataset_test)\n",
    "\n",
    "    all_predicted_labels = np.vstack(predicted_labels_list)\n",
    "    all_true_labels = np.vstack(true_labels_list)\n",
    "    all_true_labels = np.squeeze(all_true_labels)\n",
    "    mask = (all_true_labels > 0) & (all_true_labels < 1)\n",
    "    all_true_labels[mask] = 0\n",
    "    avg_metric = metric(all_true_labels, all_predicted_labels)\n",
    "\n",
    "    logger.info(f'epoch: {epoch_i}')\n",
    "\n",
    "    logger.info(\"loss_train: %0.4f| loss_valid: %0.4f|\" % (avg_train_loss, avg_val_loss))\n",
    "    for m in avg_metric:\n",
    "        logger.info(f\"metric {m} : {avg_metric[m]:.<5g}\")\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    hours = int(elapsed_time // 3600)\n",
    "    minutes = int((elapsed_time % 3600) // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    logger.info(f\"Elapsed time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bb215-7720-40a2-9a1e-42d7c450ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results model tf_efficientnet_b4.\n",
    "\n",
    "results_teacher = [{\"epoch\": 1,\n",
    "                    \"loss_train\": 0.0236,\n",
    "                    \"loss_valid\": 0.0198,\n",
    "                    \"val_RMAP\": 0.277 \n",
    "                   },\n",
    "                   {\"epoch\": 2,\n",
    "                    \"loss_train\": 0.0192,\n",
    "                    \"loss_valid\": 0.0199,\n",
    "                    \"val_RMAP\": 0.300846 \n",
    "                   },\n",
    "                   {\"epoch\": 3,\n",
    "                    \"loss_train\": 0.0177,\n",
    "                    \"loss_valid\": 0.0174,\n",
    "                    \"val_RMAP\": 0.454 \n",
    "                   },\n",
    "                    {\"epoch\": 4,\n",
    "                    \"loss_train\": 0.0175,\n",
    "                    \"loss_valid\": 0.0240,\n",
    "                    \"val_RMAP\": 0.364596 \n",
    "                   },\n",
    "                    {\"epoch\": 5,\n",
    "                    \"loss_train\": 0.0167,\n",
    "                    \"loss_valid\": 0.0376,\n",
    "                    \"val_RMAP\": 0.473289\n",
    "                   }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a714000-7183-4964-8e4c-d212178efbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3299c7-ff3a-4c76-8a21-797ca147bdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
