{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install optimum[onnxruntime] ","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:37:35.045654Z","iopub.execute_input":"2023-10-27T16:37:35.046477Z","iopub.status.idle":"2023-10-27T16:38:05.496966Z","shell.execute_reply.started":"2023-10-27T16:37:35.046420Z","shell.execute_reply":"2023-10-27T16:38:05.495203Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting optimum[onnxruntime]\n  Downloading optimum-1.13.2.tar.gz (300 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting coloredlogs (from optimum[onnxruntime])\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (1.12)\nRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (4.33.0)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (2.0.0+cpu)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (1.23.5)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (0.16.4)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (2.1.0)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (1.14.1)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime])\n  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting evaluate (from optimum[onnxruntime])\n  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]) (3.20.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (9.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[onnxruntime]) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]) (4.6.3)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]) (23.5.26)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum[onnxruntime]) (3.0.9)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum[onnxruntime]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->optimum[onnxruntime]) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime]) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime]) (0.3.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime]) (0.1.99)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum[onnxruntime])\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum[onnxruntime]) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[onnxruntime]) (1.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->optimum[onnxruntime]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->optimum[onnxruntime]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->optimum[onnxruntime]) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->optimum[onnxruntime]) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[onnxruntime]) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[onnxruntime]) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[onnxruntime]) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum[onnxruntime]) (1.16.0)\nBuilding wheels for collected packages: optimum\n  Building wheel for optimum (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=c8caf84c47953c08160390c5223d88402f99f776d2f1e5e4797a41fa83cc43a8\n  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\nSuccessfully built optimum\nInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, optimum, evaluate\nSuccessfully installed coloredlogs-15.0.1 evaluate-0.4.1 humanfriendly-10.0 onnxruntime-1.16.1 optimum-1.13.2\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers --upgrade","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:38:05.500280Z","iopub.execute_input":"2023-10-27T16:38:05.500842Z","iopub.status.idle":"2023-10-27T16:38:29.699583Z","shell.execute_reply.started":"2023-10-27T16:38:05.500792Z","shell.execute_reply":"2023-10-27T16:38:29.698147Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nCollecting transformers\n  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nCollecting tokenizers<0.15,>=0.14 (from transformers)\n  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.3\n    Uninstalling tokenizers-0.13.3:\n      Successfully uninstalled tokenizers-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\nSuccessfully installed tokenizers-0.14.1 transformers-4.34.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport os\nimport numpy as np\nfrom torch import nn\nimport torch.nn.utils.prune as prune\nimport pandas as pd\nimport transformers\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom evaluate import evaluator\nimport evaluate\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom optimum.pipelines import pipeline\nfrom optimum.onnxruntime import ORTOptimizer, ORTModelForSequenceClassification\nfrom optimum.onnxruntime.configuration import OptimizationConfig\n\nfrom tqdm import tqdm\n\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:41:05.153847Z","iopub.execute_input":"2023-10-27T16:41:05.154247Z","iopub.status.idle":"2023-10-27T16:41:05.161835Z","shell.execute_reply.started":"2023-10-27T16:41:05.154216Z","shell.execute_reply":"2023-10-27T16:41:05.160548Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Config:\n    device = \"cpu\"\n    model_checkpoint = \"unitary/toxic-bert\"\n    save_folder = 'onnx_checkpoint'\n    b_s = 16","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:38:47.472814Z","iopub.execute_input":"2023-10-27T16:38:47.473800Z","iopub.status.idle":"2023-10-27T16:38:47.483460Z","shell.execute_reply.started":"2023-10-27T16:38:47.473745Z","shell.execute_reply":"2023-10-27T16:38:47.480817Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(Config.model_checkpoint).to(Config.device)\ntokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:38:47.484822Z","iopub.execute_input":"2023-10-27T16:38:47.485776Z","iopub.status.idle":"2023-10-27T16:38:59.415170Z","shell.execute_reply.started":"2023-10-27T16:38:47.485738Z","shell.execute_reply":"2023-10-27T16:38:59.413920Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/811 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"407fbcbdb592447688ab0a36f9f62f6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a88ccf2268ea479096dea2da3c28ba18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859fcb400ee440cf8839475597540751"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7cb1dd82b8c450db20647309a4d9ad8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef9a68830984abd92e5f1c7aeae3066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13028e764c094f38838ab25d3e3aa671"}},"metadata":{}}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:38:59.419743Z","iopub.execute_input":"2023-10-27T16:38:59.420129Z","iopub.status.idle":"2023-10-27T16:39:01.309707Z","shell.execute_reply.started":"2023-10-27T16:38:59.420094Z","shell.execute_reply":"2023-10-27T16:39:01.308467Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_1 = data[data.toxic == 0].sample(20)\ndata_2 = data[data.severe_toxic == 1].sample(20)\ndata_3 = data[data.identity_hate == 1].sample(20)\ndata_4 = data[data.obscene == 1].sample(20)\ndata_5 = data[data.threat == 1].sample(20)\ndata_6 = data[data.insult == 1].sample(20)\ndata_7 = data[data.identity_hate == 1].sample(20)\ndata_8 = data.sample(100)\nnew_data = pd.concat([data_1,\n                      data_2, \n                      data_3,\n                      data_4,\n                      data_5,\n                      data_6,\n                      data_7,\n                      data_8,\n                     ]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:39:01.311177Z","iopub.execute_input":"2023-10-27T16:39:01.311563Z","iopub.status.idle":"2023-10-27T16:39:01.376928Z","shell.execute_reply.started":"2023-10-27T16:39:01.311524Z","shell.execute_reply":"2023-10-27T16:39:01.375522Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class ToxicDs(Dataset):\n    def __init__(self, data, tokenizer, length):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, ind):\n        row = self.data.iloc[ind]\n        sentence = row['comment_text']\n        bert_sentence = self.tokenizer(sentence,\n                        max_length=self.max_length,\n                        pad_to_max_length=True,\n                        add_special_tokens=True)\n\n        return {\n            \"id\": torch.LongTensor(bert_sentence['input_ids']),\n            \"mask\":  torch.LongTensor(bert_sentence['attention_mask']),                      \n        }\n    \nds = ToxicDs(new_data, length = 256, tokenizer=tokenizer)\ntoxic_dataloader = DataLoader(ds, batch_size = Config.b_s, shuffle= False, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:39:01.378577Z","iopub.execute_input":"2023-10-27T16:39:01.378968Z","iopub.status.idle":"2023-10-27T16:39:01.396553Z","shell.execute_reply.started":"2023-10-27T16:39:01.378927Z","shell.execute_reply":"2023-10-27T16:39:01.394930Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nstart_time = time.time()\nlst_times = []\nwith torch.no_grad():\n    for batch in tqdm(toxic_dataloader):\n        st_b_time = time.time()\n        ids = batch[\"id\"].to(Config.device)\n        masks = batch[\"mask\"].to(Config.device)\n        y_true = model(ids, masks)['logits']\n        lst_times.append(time.time() - st_b_time)\nfinish_time = time.time() - start_time","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:39:01.398619Z","iopub.execute_input":"2023-10-27T16:39:01.398987Z","iopub.status.idle":"2023-10-27T16:40:47.309694Z","shell.execute_reply.started":"2023-10-27T16:39:01.398959Z","shell.execute_reply":"2023-10-27T16:40:47.308229Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"  0%|          | 0/15 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n  7%|▋         | 1/15 [00:07<01:49,  7.80s/it]/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n100%|██████████| 15/15 [01:45<00:00,  7.06s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Средняя время работы на батче: {np.round(np.mean(lst_times), 3)} сек\")\nprint(f\"Общее время работы: {np.round(np.mean(finish_time), 3)} сек\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:41:08.606835Z","iopub.execute_input":"2023-10-27T16:41:08.607318Z","iopub.status.idle":"2023-10-27T16:41:08.613764Z","shell.execute_reply.started":"2023-10-27T16:41:08.607283Z","shell.execute_reply":"2023-10-27T16:41:08.612660Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Средняя время работы на батче: 7.027 сек\nОбщее время работы: 105.892 сек\n","output_type":"stream"}]},{"cell_type":"code","source":"ort_model = ORTModelForSequenceClassification.from_pretrained(Config.model_checkpoint, export=True,)\ntokenizer_ort = AutoTokenizer.from_pretrained(Config.model_checkpoint)\n# ort_model.save_pretrained(Config.save_folder)\n# tokenizer.save_pretrained(Config.save_folder)\n\nonnx_classifier = pipeline(\"text-classification\",model=ort_model,tokenizer=tokenizer_ort, device = 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:41:10.623282Z","iopub.execute_input":"2023-10-27T16:41:10.623809Z","iopub.status.idle":"2023-10-27T16:41:23.814978Z","shell.execute_reply.started":"2023-10-27T16:41:10.623766Z","shell.execute_reply":"2023-10-27T16:41:23.813702Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Framework not specified. Using pt to export to ONNX.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"269b2e3499a245d3b4761c7ec6cdc499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6543f85df07d42f99983d11512ecb110"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c5383099abb4080b06b81aae7e9152d"}},"metadata":{}},{"name":"stderr","text":"Using the export variant default. Available variants are:\n\t- default: The default ONNX variant.\nUsing framework PyTorch: 2.0.0+cpu\nOverriding 1 configuration item(s)\n\t- use_cache -> False\n","output_type":"stream"},{"name":"stdout","text":"============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n","output_type":"stream"}]},{"cell_type":"code","source":"ds_onnx = ToxicDs(new_data, length = 256, tokenizer=tokenizer_ort)\ntoxic_dataloader_onnx = DataLoader(ds_onnx, batch_size = Config.b_s, shuffle= False, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:41:25.137675Z","iopub.execute_input":"2023-10-27T16:41:25.138211Z","iopub.status.idle":"2023-10-27T16:41:25.145017Z","shell.execute_reply.started":"2023-10-27T16:41:25.138165Z","shell.execute_reply":"2023-10-27T16:41:25.143534Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\nlst_times = []\n\nfor batch in tqdm(toxic_dataloader_onnx):\n    st_b_time = time.time()\n    ids = batch[\"id\"].to(Config.device)\n    masks = batch[\"mask\"].to(Config.device)\n\n    y_true = onnx_classifier.forward({\n        \"input_ids\":ids,\n        \"attention_mask\":masks,\n        'token_type_ids': torch.ones_like(masks)\n    })\n    lst_times.append(time.time() - st_b_time)\nfinish_time = time.time() - start_time","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:41:27.546261Z","iopub.execute_input":"2023-10-27T16:41:27.546683Z","iopub.status.idle":"2023-10-27T16:43:06.671713Z","shell.execute_reply.started":"2023-10-27T16:41:27.546647Z","shell.execute_reply":"2023-10-27T16:43:06.670379Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"  0%|          | 0/15 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n100%|██████████| 15/15 [01:39<00:00,  6.61s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Средняя время работы на батче: {np.round(np.mean(lst_times), 3)} сек\")\nprint(f\"Общее время работы: {np.round(np.mean(finish_time), 3)} сек\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:43:09.827105Z","iopub.execute_input":"2023-10-27T16:43:09.827559Z","iopub.status.idle":"2023-10-27T16:43:09.834831Z","shell.execute_reply.started":"2023-10-27T16:43:09.827522Z","shell.execute_reply":"2023-10-27T16:43:09.833298Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Средняя время работы на батче: 6.592 сек\nОбщее время работы: 99.117 сек\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Ускорение общего времени работы: {((105.892 - 99.117) / 105.892 * 100):.2f}%\")\nprint(f\"Ускорение работы на батче : {((7.027 - 6.592) / 7.027 * 100):.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:48:57.860930Z","iopub.execute_input":"2023-10-27T16:48:57.861366Z","iopub.status.idle":"2023-10-27T16:48:57.867407Z","shell.execute_reply.started":"2023-10-27T16:48:57.861331Z","shell.execute_reply":"2023-10-27T16:48:57.866256Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Ускорение общего времени работы: 6.40%\nУскорение работы на батче : 6.19%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Базовая модель\nmodel_size_bytes = sum(p.numel() for p in model.parameters() if p.requires_grad) * 4\n\nmodel_size_mb = model_size_bytes / (1024 * 1024)\nprint(f\"Размер модели: {model_size_mb:.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:49:47.917474Z","iopub.execute_input":"2023-10-27T16:49:47.917932Z","iopub.status.idle":"2023-10-27T16:49:47.926413Z","shell.execute_reply.started":"2023-10-27T16:49:47.917897Z","shell.execute_reply":"2023-10-27T16:49:47.925409Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Размер модели: 417.66 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# ONNX модель\ntemp_model_path = \"temp_ort_model\"\n\nort_model.save_pretrained(temp_model_path)\nmodel_size = os.path.getsize(temp_model_path)\nmodel_size_mb = model_size_bytes / (1024 * 1024)\nprint(f\"Размер модели: {(model_size / 10):.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T16:53:32.035625Z","iopub.execute_input":"2023-10-27T16:53:32.036019Z","iopub.status.idle":"2023-10-27T16:53:33.783836Z","shell.execute_reply.started":"2023-10-27T16:53:32.035989Z","shell.execute_reply":"2023-10-27T16:53:33.782376Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Размер модели: 409.60 MB\n","output_type":"stream"}]}]}